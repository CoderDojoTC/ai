{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Teaching AI Concepts to Students 8-18 A repository for mentors who would like to teach AI to kids 8-18. It contains lesson plans and resources to make understanding AI, Machine Learning and Prediction fun and easy to understand for a wide variety of ages and backgrounds. Key Concepts Here are some key concepts we will be learning in this course. Theses questions and answers are just the beginning of our understanding of the areas around AI. What is AI? In this courese, We will define AI is the ability to learn rules from data and make predictins about the future. We will contrast AI systems from systems where we write the rules on our own. We will learn how to teach computers how to classify images and sounds. What is Prediction? Prediction is using data from the past to figure out the probability of something in the future. Prediciton is the central thing we do in AI and specificlly machine learning. What is Recomentation? Recomendation is a prediction of if a person will like a specific action. When we search for a page in a search engine like Google, the search engine is predicting what web pages it thinks we would like to see. What is Machine Learning? How is Machine Learning Different from Codeing? What is Training? What is Bias? What is Explainability? When do recomendations need to be explainable? What is a Neural Network? What is Deep Learning? Resourcese Resources","title":"Introduction"},{"location":"#teaching-ai-concepts-to-students-8-18","text":"A repository for mentors who would like to teach AI to kids 8-18. It contains lesson plans and resources to make understanding AI, Machine Learning and Prediction fun and easy to understand for a wide variety of ages and backgrounds.","title":"Teaching AI Concepts to Students 8-18"},{"location":"#key-concepts","text":"Here are some key concepts we will be learning in this course. Theses questions and answers are just the beginning of our understanding of the areas around AI.","title":"Key Concepts"},{"location":"#what-is-ai","text":"In this courese, We will define AI is the ability to learn rules from data and make predictins about the future. We will contrast AI systems from systems where we write the rules on our own. We will learn how to teach computers how to classify images and sounds.","title":"What is AI?"},{"location":"#what-is-prediction","text":"Prediction is using data from the past to figure out the probability of something in the future. Prediciton is the central thing we do in AI and specificlly machine learning.","title":"What is Prediction?"},{"location":"#what-is-recomentation","text":"Recomendation is a prediction of if a person will like a specific action. When we search for a page in a search engine like Google, the search engine is predicting what web pages it thinks we would like to see.","title":"What is Recomentation?"},{"location":"#what-is-machine-learning","text":"","title":"What is Machine Learning?"},{"location":"#how-is-machine-learning-different-from-codeing","text":"","title":"How is Machine Learning Different from Codeing?"},{"location":"#what-is-training","text":"","title":"What is Training?"},{"location":"#what-is-bias","text":"","title":"What is Bias?"},{"location":"#what-is-explainability","text":"","title":"What is Explainability?"},{"location":"#when-do-recomendations-need-to-be-explainable","text":"","title":"When do recomendations need to be explainable?"},{"location":"#what-is-a-neural-network","text":"","title":"What is a Neural Network?"},{"location":"#what-is-deep-learning","text":"","title":"What is Deep Learning?"},{"location":"#resourcese","text":"Resources","title":"Resourcese"},{"location":"contact/","text":"CoderDojo TC AI Mentor Contacts General Code Savvy Contact kidscode@codesavvy.org Specific questions on this repository Dan McCreary Dan.McCreary@gmail.com","title":"Contact"},{"location":"contact/#coderdojo-tc-ai-mentor-contacts","text":"","title":"CoderDojo TC AI Mentor Contacts"},{"location":"contact/#general-code-savvy-contact","text":"kidscode@codesavvy.org","title":"General Code Savvy Contact"},{"location":"contact/#specific-questions-on-this-repository","text":"Dan McCreary Dan.McCreary@gmail.com","title":"Specific questions on this repository"},{"location":"deep-learning-glossary/","text":"Deep Learning Glossary Core Concepts Code vs. neural networks Detrministic Functions vs. Probalistic Functions Neural Network Training Weights Error Functions Gradient Decent Testing a Neural Network Types of Neural Networks Detailed Concepts Image recognition Digit recognition Image pixels Pixel brightness Grayscale values Neural networks - overall components Input layers Hidden layers Output layers Weights Bias Nodes Counting Parameters activation activation functions probability decomposition training weighted sums normalization the sigmoid function bias parameter counting (sum of weights and bias) vector representations matrix representations linear algebra transformation functions. review of prior video in handwritten digit recognition and the structure of a neural network model the training process labels in the training set generalization test data (what you network has never seen before) testing the precision of test data MNIST training database (LeCun, Cortes, and Burges) MNIST database Finding minima like in Calculus where the slop is zero Slop of zero is a miniumum of an error Random initialization of weights A cost function - a way of telling a neural network how it can improve Adding the squares of the differences Averaging the cost of the error functions for all input data Finding the lowest cost and minimumization using a 2D visualization Using the slope as a hint on how to adjust the weights The setting slope (derative) to zero to find a minium cost Balls rolling down a hill metaphore and local miniums The role of step size when moving toward a minimum cost Moving to a 2D input model and a 3D error function Gradient function and direction of steepest decent Finding the right downhill direction vector Reference to the backpropagation algorithm (next video) Association of learning to cost function minimumization Why smoothness of a cost function is critical for gradient decent to work and how using decimal values for activation node values is important How our hope of looking for components of a line in each layer didn't work at all The neural network does not \"understand\" the shape - it can't draw any shape. There is no interpretpetable knowledge in the individual weights. This is old technology - based on a multi-layer perceptron - we can do better with modern algorithms This primitive approach is \"dumb\" - but required for us to understand modern variations like CNN and LSTM","title":"Deep Learning Glossary"},{"location":"deep-learning-glossary/#deep-learning-glossary","text":"","title":"Deep Learning Glossary"},{"location":"deep-learning-glossary/#core-concepts","text":"Code vs. neural networks Detrministic Functions vs. Probalistic Functions Neural Network Training Weights Error Functions Gradient Decent Testing a Neural Network Types of Neural Networks","title":"Core Concepts"},{"location":"deep-learning-glossary/#detailed-concepts","text":"Image recognition Digit recognition Image pixels Pixel brightness Grayscale values Neural networks - overall components Input layers Hidden layers Output layers Weights Bias Nodes Counting Parameters activation activation functions probability decomposition training weighted sums normalization the sigmoid function bias parameter counting (sum of weights and bias) vector representations matrix representations linear algebra transformation functions. review of prior video in handwritten digit recognition and the structure of a neural network model the training process labels in the training set generalization test data (what you network has never seen before) testing the precision of test data MNIST training database (LeCun, Cortes, and Burges) MNIST database Finding minima like in Calculus where the slop is zero Slop of zero is a miniumum of an error Random initialization of weights A cost function - a way of telling a neural network how it can improve Adding the squares of the differences Averaging the cost of the error functions for all input data Finding the lowest cost and minimumization using a 2D visualization Using the slope as a hint on how to adjust the weights The setting slope (derative) to zero to find a minium cost Balls rolling down a hill metaphore and local miniums The role of step size when moving toward a minimum cost Moving to a 2D input model and a 3D error function Gradient function and direction of steepest decent Finding the right downhill direction vector Reference to the backpropagation algorithm (next video) Association of learning to cost function minimumization Why smoothness of a cost function is critical for gradient decent to work and how using decimal values for activation node values is important How our hope of looking for components of a line in each layer didn't work at all The neural network does not \"understand\" the shape - it can't draw any shape. There is no interpretpetable knowledge in the individual weights. This is old technology - based on a multi-layer perceptron - we can do better with modern algorithms This primitive approach is \"dumb\" - but required for us to understand modern variations like CNN and LSTM","title":"Detailed Concepts"},{"location":"glossary/","text":"Glossary of AI Terms References WhildML Deep Learning Glossary by Denny Britz","title":"Glossary of AI Terms"},{"location":"glossary/#glossary-of-ai-terms","text":"","title":"Glossary of AI Terms"},{"location":"glossary/#references","text":"WhildML Deep Learning Glossary by Denny Britz","title":"References"},{"location":"quotes/","text":"AI Quotes Cheaper by the Month AI is becoming more powerful and radically cheaper by the month\u2014what was computationally impossible, or would cost tens of millions of dollars a few years ago, is now widespread. Mustafa Suleyman September 1st, 2023, Time","title":"Quotes"},{"location":"quotes/#ai-quotes","text":"","title":"AI Quotes"},{"location":"quotes/#cheaper-by-the-month","text":"AI is becoming more powerful and radically cheaper by the month\u2014what was computationally impossible, or would cost tens of millions of dollars a few years ago, is now widespread. Mustafa Suleyman September 1st, 2023, Time","title":"Cheaper by the Month"},{"location":"resources/","text":"Resources for teaching AI to Students Ages 8-18 We aspire to have a collection of AI activities for students that are both safe and fun. There are many AI demos available but many of them are trained on a wide range of data that could include adult content. So we need to be cautious before we recomend a specific site. With that said, here are some demonstrations that can be both safe and fun. We hope you will try them out and let us know what activities are useful in your mentoring and classrooms. Quickdraw (with Google) This fun game challenges kids to draw a picure of a named item. The students have 20 seconds to draw the item. As they draw the computer says \"I see X\" or \"I see Y\". If the computer guesses correctly you go on to the next item. You get six items in a session. Sample items are cup, clock, cellphone, lighthouse, bear etc. QuickDraw Teachable Machine This Google site is a great way to teach simple machine learning to students. Although it works on images and sounds, we use it mostly in the image mode. The site assumes you have a web camera and can hold items up to the camera for gathering training images. Students can hold up apple, a cell phone and a book and see if the computer can learn the images and then classify a new image. Teachable Machine Google Tensorflow Playground This site is excellent for helping you visualize how neural networks classify object. The interactive tool allows you to change the number of neurons and layers in a neural network and see how these changes impact a simple classifier. Google Tensorflow Playground AI and Ethics for Middle School This is a cirriculum designed by MIT professor Blakeley H. Payne. The cirriculum focuses on topics such as training, classification and bias. AI for Middle School (Course Description() AI for Middle School (Google Docs) Chatbots for Kids Chatbots can be fun, but there are many concerns about chatbots with feedback that generate bias and adult content. Althogh we recomend adult supervision for all chatbots, here is one that is relativly benign. https://www.pandorabots.com/mitsuku/ If you are interested in writing your own chatbot for a classroom activity, here are some guildlines: Chatbot Design for Kids Story Generation We are continually looking for a kid safe version of an AI story generator. If you have students that are 18 or older than you might try the Talk to Transformer demonstration. Since a small percent of their traning set is fan fiction that does have adult content, please be careful. Talk to Transformer (the free version currently shut down) Teaching AI Book This book is written from the perspective of a teacher without a strong background in AI. It includes many useful references. Teaching AI: Exploring New Frontiers for Learning by Michelle Zimmerman Conversational AI Both chatbots and Alexa apps (called \"skills\") are examples of conversational AI. Designing AI for the classroom is currently difficult. Amazon Alexa Confersational AI Deep Learning Videos The 3Blue 1 Brown Series by Grant Sanderson This series has some of the best video production value of all the intoductary videos on deep learning. It is part of the high quality Three Blue One Brown series set of videos done by Grant Sanderson of Stanford University and the Kahn Academy. The videos include many animated visual explainations that use both motion and color to describe mathematics. What is a neural network? The example used is the popular MNIST hand written digit recognition example. What we call the \"Hello world\" of AI. It walks though the process of representing digits in a 28X28 matrix of values for each digit and passing the images through a deep learing neural network. This video covers the concepts of image recognition digit recognition image pixels pixel brightness grayscale values neural networks input layers hidden layers output layers activation activation functions probability decomposition training weighted sums normalization the sigmoid function bias parameter counting (sum of weights and bias) vector representations matrix representations linear algebra transformation functions. At the end they also add a footnote on how ReLU is more common than Sibmoid. [What is a neural network?] https://www.youtube.com/watch?time_continue=5&v=aircAruvnKk&feature=emb_logo Gradient descent, how neural networks learn This is the second video. It includes concepts such as review of prior video in handwritten digit recognition and the structure of a neural network model the training process labels in the training set generalization test data (what you network has never seen before) testing the precision of test data MNIST training database (LeCun, Cortes, and Burges) MNIST database Finding minima like in Calculus where the slop is zero Slop of zero is a miniumum of an error Random initialization of weights A cost function - a way of telling a neural network how it can improve Adding the squares of the differences Averaging the cost of the error functions for all input data Finding the lowest cost and minimumization using a 2D visualization Using the slope as a hint on how to adjust the weights The setting slope (derative) to zero to find a minium cost Balls rolling down a hill metaphore and local miniums The role of step size when moving toward a minimum cost Moving to a 2D input model and a 3D error function Gradient function and direction of steepest decent Finding the right downhill direction vector Reference to the backpropagation algorithm (next video) Association of learning to cost function minimumization Why smoothness of a cost function is critical for gradient decent to work and how using decimal values for activation node values is important How our hope of looking for components of a line in each layer didn't work at all The neural network does not \"understand\" the shape - it can't draw any shape. There is no interpretpetable knowledge in the individual weights. This is old technology - based on a multi-layer perceptron - we can do better with modern algorithms This primitive approach is \"dumb\" - but required for us to understand modern variations like CNN and LSTM References from videos: [Neural Networks and Deep Learning by Michael Nielsen] (http://neuralnetworksanddeeplearning.com/) this is a free online book. Michael's strategy is to promote a deep understanding of the core concepts and their relationships rather than memorizing a shallow defintions of hundreds of terms. CS231n video","title":"Resources"},{"location":"resources/#resources-for-teaching-ai-to-students-ages-8-18","text":"We aspire to have a collection of AI activities for students that are both safe and fun. There are many AI demos available but many of them are trained on a wide range of data that could include adult content. So we need to be cautious before we recomend a specific site. With that said, here are some demonstrations that can be both safe and fun. We hope you will try them out and let us know what activities are useful in your mentoring and classrooms.","title":"Resources for teaching AI to Students Ages 8-18"},{"location":"resources/#quickdraw-with-google","text":"This fun game challenges kids to draw a picure of a named item. The students have 20 seconds to draw the item. As they draw the computer says \"I see X\" or \"I see Y\". If the computer guesses correctly you go on to the next item. You get six items in a session. Sample items are cup, clock, cellphone, lighthouse, bear etc. QuickDraw","title":"Quickdraw (with Google)"},{"location":"resources/#teachable-machine","text":"This Google site is a great way to teach simple machine learning to students. Although it works on images and sounds, we use it mostly in the image mode. The site assumes you have a web camera and can hold items up to the camera for gathering training images. Students can hold up apple, a cell phone and a book and see if the computer can learn the images and then classify a new image. Teachable Machine","title":"Teachable Machine"},{"location":"resources/#google-tensorflow-playground","text":"This site is excellent for helping you visualize how neural networks classify object. The interactive tool allows you to change the number of neurons and layers in a neural network and see how these changes impact a simple classifier. Google Tensorflow Playground","title":"Google Tensorflow Playground"},{"location":"resources/#ai-and-ethics-for-middle-school","text":"This is a cirriculum designed by MIT professor Blakeley H. Payne. The cirriculum focuses on topics such as training, classification and bias. AI for Middle School (Course Description() AI for Middle School (Google Docs)","title":"AI and Ethics for Middle School"},{"location":"resources/#chatbots-for-kids","text":"Chatbots can be fun, but there are many concerns about chatbots with feedback that generate bias and adult content. Althogh we recomend adult supervision for all chatbots, here is one that is relativly benign. https://www.pandorabots.com/mitsuku/ If you are interested in writing your own chatbot for a classroom activity, here are some guildlines: Chatbot Design for Kids","title":"Chatbots for Kids"},{"location":"resources/#story-generation","text":"We are continually looking for a kid safe version of an AI story generator. If you have students that are 18 or older than you might try the Talk to Transformer demonstration. Since a small percent of their traning set is fan fiction that does have adult content, please be careful. Talk to Transformer (the free version currently shut down)","title":"Story Generation"},{"location":"resources/#teaching-ai-book","text":"This book is written from the perspective of a teacher without a strong background in AI. It includes many useful references. Teaching AI: Exploring New Frontiers for Learning by Michelle Zimmerman","title":"Teaching AI Book"},{"location":"resources/#conversational-ai","text":"Both chatbots and Alexa apps (called \"skills\") are examples of conversational AI. Designing AI for the classroom is currently difficult. Amazon Alexa Confersational AI","title":"Conversational AI"},{"location":"resources/#deep-learning-videos","text":"","title":"Deep Learning Videos"},{"location":"resources/#the-3blue-1-brown-series-by-grant-sanderson","text":"This series has some of the best video production value of all the intoductary videos on deep learning. It is part of the high quality Three Blue One Brown series set of videos done by Grant Sanderson of Stanford University and the Kahn Academy. The videos include many animated visual explainations that use both motion and color to describe mathematics.","title":"The 3Blue 1 Brown Series by Grant Sanderson"},{"location":"resources/#what-is-a-neural-network","text":"The example used is the popular MNIST hand written digit recognition example. What we call the \"Hello world\" of AI. It walks though the process of representing digits in a 28X28 matrix of values for each digit and passing the images through a deep learing neural network. This video covers the concepts of image recognition digit recognition image pixels pixel brightness grayscale values neural networks input layers hidden layers output layers activation activation functions probability decomposition training weighted sums normalization the sigmoid function bias parameter counting (sum of weights and bias) vector representations matrix representations linear algebra transformation functions. At the end they also add a footnote on how ReLU is more common than Sibmoid. [What is a neural network?] https://www.youtube.com/watch?time_continue=5&v=aircAruvnKk&feature=emb_logo","title":"What is a neural network?"},{"location":"resources/#gradient-descent-how-neural-networks-learn","text":"This is the second video. It includes concepts such as review of prior video in handwritten digit recognition and the structure of a neural network model the training process labels in the training set generalization test data (what you network has never seen before) testing the precision of test data MNIST training database (LeCun, Cortes, and Burges) MNIST database Finding minima like in Calculus where the slop is zero Slop of zero is a miniumum of an error Random initialization of weights A cost function - a way of telling a neural network how it can improve Adding the squares of the differences Averaging the cost of the error functions for all input data Finding the lowest cost and minimumization using a 2D visualization Using the slope as a hint on how to adjust the weights The setting slope (derative) to zero to find a minium cost Balls rolling down a hill metaphore and local miniums The role of step size when moving toward a minimum cost Moving to a 2D input model and a 3D error function Gradient function and direction of steepest decent Finding the right downhill direction vector Reference to the backpropagation algorithm (next video) Association of learning to cost function minimumization Why smoothness of a cost function is critical for gradient decent to work and how using decimal values for activation node values is important How our hope of looking for components of a line in each layer didn't work at all The neural network does not \"understand\" the shape - it can't draw any shape. There is no interpretpetable knowledge in the individual weights. This is old technology - based on a multi-layer perceptron - we can do better with modern algorithms This primitive approach is \"dumb\" - but required for us to understand modern variations like CNN and LSTM","title":"Gradient descent, how neural networks learn"},{"location":"resources/#references-from-videos","text":"[Neural Networks and Deep Learning by Michael Nielsen] (http://neuralnetworksanddeeplearning.com/) this is a free online book. Michael's strategy is to promote a deep understanding of the core concepts and their relationships rather than memorizing a shallow defintions of hundreds of terms. CS231n video","title":"References from videos:"},{"location":"labs/","text":"AI Hands-On Labs Quick, Draw! Teachable Machine Bias in BERT","title":"AI Hands-On Labs"},{"location":"labs/#ai-hands-on-labs","text":"","title":"AI Hands-On Labs"},{"location":"labs/#quick-draw","text":"","title":"Quick, Draw!"},{"location":"labs/#teachable-machine","text":"","title":"Teachable Machine"},{"location":"labs/#bias-in-bert","text":"","title":"Bias in BERT"},{"location":"labs/bias/","text":"Bias in Large-Language Models In this lab, we will explore the topic of gender bias in large-language models. Specifically, we will look at how occupations are biased in the BERT large-language model. !!! Warning This lab can be controversial. It has shown to create strong emotions about fairness in our society. Dan's Blog","title":"Bias in Large-Language Models"},{"location":"labs/bias/#bias-in-large-language-models","text":"In this lab, we will explore the topic of gender bias in large-language models. Specifically, we will look at how occupations are biased in the BERT large-language model. !!! Warning This lab can be controversial. It has shown to create strong emotions about fairness in our society. Dan's Blog","title":"Bias in Large-Language Models"},{"location":"labs/quickdraw/","text":"Quick Draw Lab Quick Draw is a fun game that can be played by anyone who can use a mouse. It is a machine-learning web application that will try to guess what you are drawing. It is a great way to introduce kids to machine learning and prediction. QuickDraw is similar to the game Pictionary in that the player only has a limited time to draw and item. But in this case, the computer is trying to guess what you are drawing. QuickDraw was created by the engineers at Google and is kid-safe. It is free and does not gather and store any personal information. How it Works QuickDraw will suggest an item to draw such as \"bicycle\". You then have 20 seconds to draw that item while an AI agent will try to guess what you are drawing. This repeats six times. At the end of the game Quick Steps Have kids play one or more rounds of QuickDraw. Then ask some questions: How long did it take QuickDraw to guess what you were trying to draw? How good was it at guessing? Were all the drawing the same level of difficulty to draw? How many items do you think it was comparing your drawing with? How do you think QuickDraw \"learned\" to match drawings and the names of items? How is \"prediction\" involved in QuickDraw? Could QuickDraw give you detailed explanations of why it guessed specific items? When is it important for an AI to give you explanations of why it has made a decision? Is explainable AI important if healthcare? What is \"similarity\" in the context of QuickDraw? Look at the data used to train QuickDraw. What did you learn from this data? Look at the categories of items. Is this list of items biased in any way? Are insects fairly represented? If you had to write your own version of QuickDraw, how would you go about doing it? More to Explore If your class has some experience with Python, have them do a search for \"Quick, Draw\" on GitHub. What do you find? References Anubhav Shrimal's GitHub repo Chandra Kanth GitHub repo Machine Learning on Wikipedia Explainable AI on Wikipedia","title":"Quick, Draw"},{"location":"labs/quickdraw/#quick-draw-lab","text":"Quick Draw is a fun game that can be played by anyone who can use a mouse. It is a machine-learning web application that will try to guess what you are drawing. It is a great way to introduce kids to machine learning and prediction. QuickDraw is similar to the game Pictionary in that the player only has a limited time to draw and item. But in this case, the computer is trying to guess what you are drawing. QuickDraw was created by the engineers at Google and is kid-safe. It is free and does not gather and store any personal information.","title":"Quick Draw Lab"},{"location":"labs/quickdraw/#how-it-works","text":"QuickDraw will suggest an item to draw such as \"bicycle\". You then have 20 seconds to draw that item while an AI agent will try to guess what you are drawing. This repeats six times. At the end of the game Quick","title":"How it Works"},{"location":"labs/quickdraw/#steps","text":"Have kids play one or more rounds of QuickDraw. Then ask some questions: How long did it take QuickDraw to guess what you were trying to draw? How good was it at guessing? Were all the drawing the same level of difficulty to draw? How many items do you think it was comparing your drawing with? How do you think QuickDraw \"learned\" to match drawings and the names of items? How is \"prediction\" involved in QuickDraw? Could QuickDraw give you detailed explanations of why it guessed specific items? When is it important for an AI to give you explanations of why it has made a decision? Is explainable AI important if healthcare? What is \"similarity\" in the context of QuickDraw? Look at the data used to train QuickDraw. What did you learn from this data? Look at the categories of items. Is this list of items biased in any way? Are insects fairly represented? If you had to write your own version of QuickDraw, how would you go about doing it?","title":"Steps"},{"location":"labs/quickdraw/#more-to-explore","text":"If your class has some experience with Python, have them do a search for \"Quick, Draw\" on GitHub. What do you find?","title":"More to Explore"},{"location":"labs/quickdraw/#references","text":"Anubhav Shrimal's GitHub repo Chandra Kanth GitHub repo Machine Learning on Wikipedia Explainable AI on Wikipedia","title":"References"},{"location":"labs/teachable-machine/","text":"Teachable Machine Teachable Machine With Google","title":"Teachable Machine"},{"location":"labs/teachable-machine/#teachable-machine","text":"Teachable Machine With Google","title":"Teachable Machine"}]}